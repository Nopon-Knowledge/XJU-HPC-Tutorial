# 深度学习环境依赖配置教程

## 1、安装基础Python环境

由于高算平台无法连接外网，因此我们必须使用whl即离线安装包来安装项目所需的依赖环境，这一部分很重要，
也是在该平台运行深度学习项目最麻烦的一个环节，接下来将详细介绍环境配置的流程。

首先，我们需要初始化python基础环境，这里需要用到 [linux_init_venv.sh](linux_init_venv.sh)，该脚本用作linux远程虚拟环境初始化。
只需要注意第8，9行（命令如下），将其修改为你想要的路径。

   ```
   VENV_DIR="${VENV_DIR:-$HOME/venvs/test_env}" #可以改为你想要的环境路径
   PYBASE="${PYBASE:-/storage/software/anaconda3/bin/python}" #选择python来源，该默认路径的python为3.9版本
   ```

之后，在远程终端输入如下命令完成基础环境搭建。
   ```
   bash ~/python_project/test/linux_init_venv.sh
   ```
搭建完成后，可以使用source命令激活。（目前该教程中没有使用conda管理环境，因为该作业系统提交作业时需要指定环境，
所以没有必要再使用conda activate指定环境了）
   ```
   source "~/venvs/test_env/bin/activate"
   ```
激活后，远程终端用户名前会出现环境名，此时可以输入python测试该环境的python版本。

## 2、下载并上传项目所需依赖的轮子

第二步，我们需要使用 [win_makewhl.ps1](win_makewhl.ps1) （macos请使用 [macos_makewhl.sh](macos_makewhl.sh)），
该脚本为windows的powershell脚本，作用是下载深度学习所需的环境依赖，里面已经内置了部分通用依赖，如numpy、matplotlib、tensorboard等等，
默认的pytorch版本为2.4.1+cu121。

只需要关注 18、19、67行，即python版本、cuda版本和pytorch版本，填写完这些之后，那些cuda依赖库应该没人知道要填什么版本，
此时我们需要将该命令交给AI（推荐使用chatgpt），告诉他你要的python版本、cuda版本和pytorch版本，将该脚本内的其它依赖库改为对应版本即可。

   ```
   $PYVER  = 39            # 目标python版本
   $CUDA   = 'cu121'       # 指定cuda版本，如想要cuda12.1，则输入cu121，如想要cpu，则输入cpu
   ...
   ...
   ...
   $TORCH_TRIPLE = @('torch==2.4.1','torchvision==0.19.1','torchaudio==2.4.1') #填写所需的pytorch版本
   ```

更改完成后，使用如下命令运行
   ```
   powershell -NoProfile -ExecutionPolicy Bypass -File .\win_makewhl.ps1
   ```
macos使用
   ```
   bash mmacos_makewhl.sh
   ```
运行成功后，项目内应出现一个压缩包，如下图所示

<p align="center">
<img src="../images/local_download_zip.png" width="50%" alt="本地下载后的压缩包">
</p>

右击该压缩包，选择部署，上传至远程服务器，上传成功后，运行[linux_unzip.sh](linux_unzip.sh)脚本解压缩，
该脚本需要关注5、6行，分别为待解压文件所在路径和解压目标路径。（该操作也可以在web端的图形交互界面完成）
   ```
   ZIP="/storage/home/201400920/wheelhouse-py39-cu121-202511031722.zip" #带解压文件所在路径
   DEST="/storage/home/201400920/library/wheelhouse" #解压目标路径
   ```

## 3、将轮子安装至环境中

解压成功后，运行[linux_installpkgs.sh](linux_installpkgs.sh)脚本来安装我们所需的环境，该脚本主要关注7、8行。
   ```
   DEST="${DEST:-$HOME/library/wheelhouse}" # 安装包所在路径
   PIP="${PIP:-$HOME/venvs/test_env/bin/pip}"   # 环境路径，由想要安装到哪个环境决定
   ```

安装过程往往一次性不会成功，可能会报错显示缺少某些依赖，此时往往只缺失数量较少的依赖，这种少数依赖使用makewhl脚本显然不合适，
我们需要准备一个下载少量依赖的脚本，该脚本为[win_patch.ps1](win_patch.ps1)，主要关注第二行，和第三行开始的数组，
将你所需的依赖包写进该数组， 然后让AI帮忙更改下面的条件命令。
   ```
   $PYVER = 39
   $ADD = @(
       'nvidia-curand-cu12==10.3.2.106'
   )
   ```
少量依赖可以直接使用以下命令安装:
   ```
   PIP="$HOME/venvs/test_env/bin/pip"
   DEST="$HOME/library/wheelhouse"
   "$PIP" install --no-index --find-links "$DEST" einops==0.7.0
   ```

全部安装完成后，运行以下命令
   ```
   pytorch及cuda测试：
   jsub -m gpu01 -q gpu -gpgpu 1 -W 00:01 -o "$HOME/logs/output.%J" -e "$HOME/logs/error.%J" -cwd "$HOME/python_project/test" "$HOME/venvs/test_env/bin/python" test_pytorch.py
   ```
如果最终得到如下图所示的输出，则说明pytorch及cuda配置完成。
<p align="center">
    <img src="../images/testpy.png" width="70%" alt="测试pytorch的运行结果">
</p>